student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer
Hello, enter some text or 'e'  to exit
> hello
You entered: hello

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.h  README.md  tokenizer    tokenizer.c~  tokenizer.o
Makefile   tester.c   tokenizer.c  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o tokenizer.o tokenizer.c
tokenizer.c: In function ‘tokenize’:
tokenizer.c:75:15: warning: comparison between pointer and zero character constant [-Wpointer-compare]
   while(token != '\0') {
               ^~
tokenizer.c:75:9: note: did you mean to dereference the pointer?
   while(token != '\0') {
         ^
tokenizer.c: In function ‘print_tokens’:
tokenizer.c:87:28: warning: comparison between pointer and zero character constant [-Wpointer-compare]
   for(int i = 0; tokens[i] != '\0'; i++) {
                            ^~
tokenizer.c:87:18: note: did you mean to dereference the pointer?
   for(int i = 0; tokens[i] != '\0'; i++) {
                  ^
tokenizer.c: In function ‘free_tokens’:
tokenizer.c:97:29: warning: comparison between pointer and zero character constant [-Wpointer-compare]
   for (int i = 0; tokens[i] != '\0'; i++) {
                             ^~
tokenizer.c:97:19: note: did you mean to dereference the pointer?
   for (int i = 0; tokens[i] != '\0'; i++) {
                   ^
gcc -o tokenizer tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.h  README.md  tokenizer    tokenizer.c~  tokenizer.o
Makefile   tester.c   tokenizer.c  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o tokenizer.o tokenizer.c
tokenizer.c: In function ‘print_tokens’:
tokenizer.c:87:28: warning: comparison between pointer and zero character constant [-Wpointer-compare]
   for(int i = 0; tokens[i] != '\0'; i++) {
                            ^~
tokenizer.c:87:18: note: did you mean to dereference the pointer?
   for(int i = 0; tokens[i] != '\0'; i++) {
                  ^
tokenizer.c: In function ‘free_tokens’:
tokenizer.c:97:29: warning: comparison between pointer and zero character constant [-Wpointer-compare]
   for (int i = 0; tokens[i] != '\0'; i++) {
                             ^~
tokenizer.c:97:19: note: did you mean to dereference the pointer?
   for (int i = 0; tokens[i] != '\0'; i++) {
                   ^
gcc -o tokenizer tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.h  README.md  tokenizer    tokenizer.c~  tokenizer.o
Makefile   tester.c   tokenizer.c  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o tokenizer.o tokenizer.c
gcc -o tokenizer tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer
Hello, enter some text or 'e'  to exit
> hello
You entered: hello

> hi
You entered: hi

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git add .
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git commit
error: Terminal is dumb, but EDITOR unset
Please supply the message using either -m or -F option.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git add .
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git commit -m "first"
[master 87620f5] first
 4 files changed, 212 insertions(+)
 create mode 100644 src/Makefile
 create mode 100755 src/tokenizer
 create mode 100644 src/tokenizer.c
 create mode 100644 src/tokenizer.c~
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git push
Counting objects: 7, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (7/7), done.
Writing objects: 100% (7/7), 6.03 KiB | 6.03 MiB/s, done.
Total 7 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2), completed with 1 local object.        
To https://github.com/utep-cs-systems-courses/f24-corg-tokenizer-AndyR-11.git
   cdca691..87620f5  master -> master
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.h  main.c~   README.md  tokenizer    tokenizer.c~  tokenizer.o
main.c     Makefile  tester.c   tokenizer.c  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> makefile
If 'makefile' is not a typo you can use command-not-found to lookup the package that contains it, like this:
    cnf makefile
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer
Hello, enter some text or 'e'  to exit
> hello
You entered: hello

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make clean
rm -f *.o tokenizer
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make clean
rm -f *.o tokenizer
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git add .
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git commit -m "first edit"
[master b2cc039] first edit
 3 files changed, 71 insertions(+)
 create mode 100644 src/main.c
 create mode 100644 src/main.c~
 delete mode 100755 src/tokenizer
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git push
Counting objects: 5, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (5/5), done.
Writing objects: 100% (5/5), 874 bytes | 874.00 KiB/s, done.
Total 5 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2), completed with 2 local objects.        
To https://github.com/utep-cs-systems-courses/f24-corg-tokenizer-AndyR-11.git
   87620f5..b2cc039  master -> master
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.h  main.c  main.c~  Makefile  README.md  tester.c  tokenizer.c  tokenizer.c~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: *** No rule to make target 'uimain.c', needed by 'uimain.o'.  Stop.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.h  main.c  main.c~  Makefile  README.md  tester.c  tokenizer.c  tokenizer.c~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> main
If 'main' is not a typo you can use command-not-found to lookup the package that contains it, like this:
    cnf main
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
gcc -c main.c
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer
bash: ./tokenizer: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
bash: ./main: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.h  main.c~  Makefile   tester.c     tokenizer.c~
main.c     main.o   README.md  tokenizer.c  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'main.o' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
bash: ./main: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
bash: ./main: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.h  main.c~  Makefile   tester.c     tokenizer.c~
main.c     main.o   README.md  tokenizer.c  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o tokenizer.o tokenizer.c
gcc -o tokenizer tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer
Hello, enter some text or 'e'  to exit
> helo
You entered: helo

> 
You entered: 

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.h  main.c~  Makefile   tester.c   tokenizer.c   tokenizer.h
main.c     main.o   README.md  tokenizer  tokenizer.c~  tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
In file included from main.c:3:0:
tokenizer.c:103:1: error: unterminated comment
 /*#define MAX_STR_LENGTH 100
 ^
make: *** [<builtin>: main.o] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o main main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
Hello, enter some text or 'e'  to exit
> hello
You entered: hello

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c  main    main.c~  Makefile   tester.c   #tokenizer.c#  tokenizer.c~  tokenizer.o
history.h  main.c  main.o   README.md  tokenizer  tokenizer.c    tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o history.o history.c
history.c: In function ‘add_history’:
history.c:15:16: error: ‘tokenHistory’ undeclared (first use in this function); did you mean ‘token_start’?
   Item *node = tokenHistory -> root;
                ^~~~~~~~~~~~
                token_start
history.c:15:16: note: each undeclared identifier is reported only once for each function it appears in
history.c:19:5: error: ‘pos’ undeclared (first use in this function)
     pos++;
     ^~~
history.c: In function ‘print_history’:
history.c:43:5: warning: implicit declaration of function ‘print’; did you mean ‘printf’? [-Wimplicit-function-declaration]
     print("%d: %s\n", current -> id, current -> str);
     ^~~~~
     printf
make: *** [<builtin>: history.o] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.h  main.c   main.o    README.md  tokenizer      tokenizer.c   tokenizer.h
history.c~  main       main.c~  Makefile  tester.c   #tokenizer.c#  tokenizer.c~  tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o history.o history.c
cc    -c -o tokenizer.o tokenizer.c
gcc -o tokenizer history.o tokenizer.o main.o
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `space_char':
main.c:(.text+0x0): multiple definition of `space_char'; tokenizer.o:tokenizer.c:(.text+0x0): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `non_space_char':
main.c:(.text+0x29): multiple definition of `non_space_char'; tokenizer.o:tokenizer.c:(.text+0x29): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_start':
main.c:(.text+0x52): multiple definition of `token_start'; tokenizer.o:tokenizer.c:(.text+0x52): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_terminator':
main.c:(.text+0xae): multiple definition of `token_terminator'; tokenizer.o:tokenizer.c:(.text+0xae): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `count_tokens':
main.c:(.text+0xdc): multiple definition of `count_tokens'; tokenizer.o:tokenizer.c:(.text+0xdc): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `copy_str':
main.c:(.text+0x131): multiple definition of `copy_str'; tokenizer.o:tokenizer.c:(.text+0x131): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `tokenize':
main.c:(.text+0x1a3): multiple definition of `tokenize'; tokenizer.o:tokenizer.c:(.text+0x1a3): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `print_tokens':
main.c:(.text+0x27c): multiple definition of `print_tokens'; tokenizer.o:tokenizer.c:(.text+0x27c): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `free_tokens':
main.c:(.text+0x2df): multiple definition of `free_tokens'; tokenizer.o:tokenizer.c:(.text+0x2df): first defined here
collect2: error: ld returned 1 exit status
make: *** [Makefile:3: tokenizer] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
gcc -o tokenizer history.o tokenizer.o main.o
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `space_char':
main.c:(.text+0x0): multiple definition of `space_char'; tokenizer.o:tokenizer.c:(.text+0x0): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `non_space_char':
main.c:(.text+0x29): multiple definition of `non_space_char'; tokenizer.o:tokenizer.c:(.text+0x29): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_start':
main.c:(.text+0x52): multiple definition of `token_start'; tokenizer.o:tokenizer.c:(.text+0x52): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_terminator':
main.c:(.text+0xae): multiple definition of `token_terminator'; tokenizer.o:tokenizer.c:(.text+0xae): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `count_tokens':
main.c:(.text+0xdc): multiple definition of `count_tokens'; tokenizer.o:tokenizer.c:(.text+0xdc): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `copy_str':
main.c:(.text+0x131): multiple definition of `copy_str'; tokenizer.o:tokenizer.c:(.text+0x131): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `tokenize':
main.c:(.text+0x1a3): multiple definition of `tokenize'; tokenizer.o:tokenizer.c:(.text+0x1a3): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `print_tokens':
main.c:(.text+0x27c): multiple definition of `print_tokens'; tokenizer.o:tokenizer.c:(.text+0x27c): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `free_tokens':
main.c:(.text+0x2df): multiple definition of `free_tokens'; tokenizer.o:tokenizer.c:(.text+0x2df): first defined here
collect2: error: ld returned 1 exit status
make: *** [Makefile:3: tokenizer] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.h  main    main.c~  Makefile   tester.c       tokenizer.c   tokenizer.h
history.c~  history.o  main.c  main.o   README.md  #tokenizer.c#  tokenizer.c~  tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
gcc -o tokenizer history.o tokenizer.o main.o
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `space_char':
main.c:(.text+0x0): multiple definition of `space_char'; tokenizer.o:tokenizer.c:(.text+0x0): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `non_space_char':
main.c:(.text+0x29): multiple definition of `non_space_char'; tokenizer.o:tokenizer.c:(.text+0x29): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_start':
main.c:(.text+0x52): multiple definition of `token_start'; tokenizer.o:tokenizer.c:(.text+0x52): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_terminator':
main.c:(.text+0xae): multiple definition of `token_terminator'; tokenizer.o:tokenizer.c:(.text+0xae): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `count_tokens':
main.c:(.text+0xdc): multiple definition of `count_tokens'; tokenizer.o:tokenizer.c:(.text+0xdc): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `copy_str':
main.c:(.text+0x131): multiple definition of `copy_str'; tokenizer.o:tokenizer.c:(.text+0x131): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `tokenize':
main.c:(.text+0x1a3): multiple definition of `tokenize'; tokenizer.o:tokenizer.c:(.text+0x1a3): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `print_tokens':
main.c:(.text+0x27c): multiple definition of `print_tokens'; tokenizer.o:tokenizer.c:(.text+0x27c): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `free_tokens':
main.c:(.text+0x2df): multiple definition of `free_tokens'; tokenizer.o:tokenizer.c:(.text+0x2df): first defined here
collect2: error: ld returned 1 exit status
make: *** [Makefile:3: tokenizer] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make clean
rm -f *.o tokenizer
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.h  main.c   Makefile   tester.c       tokenizer.c   tokenizer.h
history.c~  main       main.c~  README.md  #tokenizer.c#  tokenizer.c~
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o history.o history.c
cc    -c -o tokenizer.o tokenizer.c
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `space_char':
main.c:(.text+0x0): multiple definition of `space_char'; tokenizer.o:tokenizer.c:(.text+0x0): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `non_space_char':
main.c:(.text+0x29): multiple definition of `non_space_char'; tokenizer.o:tokenizer.c:(.text+0x29): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_start':
main.c:(.text+0x52): multiple definition of `token_start'; tokenizer.o:tokenizer.c:(.text+0x52): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_terminator':
main.c:(.text+0xae): multiple definition of `token_terminator'; tokenizer.o:tokenizer.c:(.text+0xae): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `count_tokens':
main.c:(.text+0xdc): multiple definition of `count_tokens'; tokenizer.o:tokenizer.c:(.text+0xdc): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `copy_str':
main.c:(.text+0x131): multiple definition of `copy_str'; tokenizer.o:tokenizer.c:(.text+0x131): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `tokenize':
main.c:(.text+0x1a3): multiple definition of `tokenize'; tokenizer.o:tokenizer.c:(.text+0x1a3): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `print_tokens':
main.c:(.text+0x27c): multiple definition of `print_tokens'; tokenizer.o:tokenizer.c:(.text+0x27c): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `free_tokens':
main.c:(.text+0x2df): multiple definition of `free_tokens'; tokenizer.o:tokenizer.c:(.text+0x2df): first defined here
collect2: error: ld returned 1 exit status
make: *** [Makefile:3: tokenizer] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  #tokenizer.c#  tokenizer.h
history.c~  main       main.o    #*shell*#  tokenizer.c    tokenizer.o
history.h   main.c     Makefile  tester.c   tokenizer.c~
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
Hello, enter some text or 'e'  to exit
> hello
You entered: hello

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  #tokenizer.c#   tokenizer.c~
history.c~  main       main.o    #*shell*#  #tokenizer.c#~  tokenizer.h
history.h   main.c     Makefile  tester.c   tokenizer.c     tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
gcc -o tokenizer history.o tokenizer.o main.o
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `space_char':
main.c:(.text+0x0): multiple definition of `space_char'; tokenizer.o:tokenizer.c:(.text+0x0): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `non_space_char':
main.c:(.text+0x29): multiple definition of `non_space_char'; tokenizer.o:tokenizer.c:(.text+0x29): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_start':
main.c:(.text+0x52): multiple definition of `token_start'; tokenizer.o:tokenizer.c:(.text+0x52): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_terminator':
main.c:(.text+0xae): multiple definition of `token_terminator'; tokenizer.o:tokenizer.c:(.text+0xae): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `count_tokens':
main.c:(.text+0xdc): multiple definition of `count_tokens'; tokenizer.o:tokenizer.c:(.text+0xdc): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `copy_str':
main.c:(.text+0x131): multiple definition of `copy_str'; tokenizer.o:tokenizer.c:(.text+0x131): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `tokenize':
main.c:(.text+0x1a3): multiple definition of `tokenize'; tokenizer.o:tokenizer.c:(.text+0x1a3): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `print_tokens':
main.c:(.text+0x27c): multiple definition of `print_tokens'; tokenizer.o:tokenizer.c:(.text+0x27c): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `free_tokens':
main.c:(.text+0x2df): multiple definition of `free_tokens'; tokenizer.o:tokenizer.c:(.text+0x2df): first defined here
collect2: error: ld returned 1 exit status
make: *** [Makefile:3: tokenizer] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  #tokenizer.c#   tokenizer.c~
history.c~  main       main.o    #*shell*#  #tokenizer.c#~  tokenizer.h
history.h   main.c     Makefile  tester.c   tokenizer.c     tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o history.o history.c
gcc -o tokenizer history.o tokenizer.o main.o
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `space_char':
main.c:(.text+0x0): multiple definition of `space_char'; tokenizer.o:tokenizer.c:(.text+0x0): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `non_space_char':
main.c:(.text+0x29): multiple definition of `non_space_char'; tokenizer.o:tokenizer.c:(.text+0x29): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_start':
main.c:(.text+0x52): multiple definition of `token_start'; tokenizer.o:tokenizer.c:(.text+0x52): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `token_terminator':
main.c:(.text+0xae): multiple definition of `token_terminator'; tokenizer.o:tokenizer.c:(.text+0xae): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `count_tokens':
main.c:(.text+0xdc): multiple definition of `count_tokens'; tokenizer.o:tokenizer.c:(.text+0xdc): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `copy_str':
main.c:(.text+0x131): multiple definition of `copy_str'; tokenizer.o:tokenizer.c:(.text+0x131): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `tokenize':
main.c:(.text+0x1a3): multiple definition of `tokenize'; tokenizer.o:tokenizer.c:(.text+0x1a3): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `print_tokens':
main.c:(.text+0x27c): multiple definition of `print_tokens'; tokenizer.o:tokenizer.c:(.text+0x27c): first defined here
/usr/lib64/gcc/x86_64-suse-linux/7/../../../../x86_64-suse-linux/bin/ld: main.o: in function `free_tokens':
main.c:(.text+0x2df): multiple definition of `free_tokens'; tokenizer.o:tokenizer.c:(.text+0x2df): first defined here
collect2: error: ld returned 1 exit status
make: *** [Makefile:3: tokenizer] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer
bash: ./tokenizer: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
Hello, enter some text or 'e'  to exit
> hello
You entered: hello

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  #tokenizer.c#   tokenizer.c~
history.c~  main       main.o    #*shell*#  #tokenizer.c#~  tokenizer.h
history.h   main.c     Makefile  tester.c   tokenizer.c     tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> makin
If 'makin' is not a typo you can use command-not-found to lookup the package that contains it, like this:
    cnf makin
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
Hello, enter some text or 'e'  to exit
> hello
You entered: hello

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  tokenizer       tokenizer.c   tokenizer.o
history.c~  main       main.o    #*shell*#  #tokenizer.c#   tokenizer.c~
history.h   main.c     Makefile  tester.c   #tokenizer.c#~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
Hello, enter some text or 'e'  to exit
> hello
You entered: hello

> hi
You entered: hi

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  tokenizer       tokenizer.c   tokenizer.o
history.c~  main       main.o    #*shell*#  #tokenizer.c#   tokenizer.c~
history.h   main.c     Makefile  tester.c   #tokenizer.c#~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git add .
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git commit -m "edited history.c"
[master 427d44b] edited history.c
 14 files changed, 691 insertions(+), 3 deletions(-)
 create mode 100644 src/#*shell*#
 create mode 100644 src/#main.c#
 create mode 100644 src/#tokenizer.c#
 create mode 100644 src/#tokenizer.c#~
 create mode 120000 src/.#*shell*
 create mode 120000 src/.#main.c
 create mode 120000 src/.#tokenizer.c
 create mode 100644 src/history.c
 create mode 100644 src/history.c~
 create mode 100755 src/main
 create mode 100755 src/tokenizer
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git push
Counting objects: 15, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (13/13), done.
Writing objects: 100% (15/15), 10.83 KiB | 2.71 MiB/s, done.
Total 15 (delta 6), reused 0 (delta 0)
remote: Resolving deltas: 100% (6/6), completed with 3 local objects.        
To https://github.com/utep-cs-systems-courses/f24-corg-tokenizer-AndyR-11.git
   b2cc039..427d44b  master -> master
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make clean
rm -f *.o tokenizer
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git add .
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git commit -m ""
Aborting commit due to empty commit message.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git add .
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git commit -m "edited history.c"
[master 417568f] edited history.c
 1 file changed, 0 insertions(+), 0 deletions(-)
 delete mode 100755 src/tokenizer
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git push
Counting objects: 3, done.
Delta compression using up to 2 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 292 bytes | 292.00 KiB/s, done.
Total 3 (delta 2), reused 0 (delta 0)
remote: Resolving deltas: 100% (2/2), completed with 2 local objects.        
To https://github.com/utep-cs-systems-courses/f24-corg-tokenizer-AndyR-11.git
   427d44b..417568f  master -> master
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.h  main.c   Makefile   #*shell*#  #tokenizer.c#   tokenizer.c   tokenizer.h
history.c~  main       main.c~  README.md  tester.c   #tokenizer.c#~  tokenizer.c~
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o history.o history.c
cc    -c -o tokenizer.o tokenizer.c
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
Hello, enter some text or 'e'  to exit
> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  tokenizer       tokenizer.c   tokenizer.o
history.c~  main       main.o    #*shell*#  #tokenizer.c#   tokenizer.c~
history.h   main.c     Makefile  tester.c   #tokenizer.c#~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./main
Hello, enter some text or 'e'  to exit
> hello
You entered: hello

> hi
You entered: hi

> e
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c   Makefile   tester.c       #tokenizer.c#~  tokenizer.h
history.c~  main       main.c~  README.md  tokenizer      tokenizer.c     tokenizer.o
history.h   #main.c#   main.o   #*shell*#  #tokenizer.c#  tokenizer.c~
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> t
Please enter your sentence:
>Hello I am here

tokens[0] = Hello I am here

Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> h
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> hi
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> h
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c   Makefile   tester.c       #tokenizer.c#~  tokenizer.h
history.c~  main       main.c~  README.md  tokenizer      tokenizer.c     tokenizer.o
history.h   #main.c#   main.o   #*shell*#  #tokenizer.c#  tokenizer.c~
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tok
bash: ./tok: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> t
Please enter your sentence:
>hi

tokens[0] = hi

Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  tokenizer       tokenizer.c~
history.c~  main       main.o    #*shell*#  #tokenizer.c#~  tokenizer.h
history.h   main.c     Makefile  tester.c   tokenizer.c     tokenizer.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o tokenizer.o tokenizer.c
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> t
Please enter your sentence:
>hi i

tokens[0] = hi
tokens[1] = i

Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> t
Please enter your sentence:
>Hello my name is andy

tokens[0] = Hello
tokens[1] = my
tokens[2] = name
tokens[3] = is
tokens[4] = andy

Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> t
Please enter your sentence:
>hello how are you

tokens[0] = hello
tokens[1] = how
tokens[2] = are
tokens[3] = you

Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o tokenizer.o tokenizer.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> t
Please enter your sentence:
>hello hi you

tokens[0] = hello
tokens[1] = hi
tokens[2] = you

Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> t
Please enter your sentence:
>hello hi

tokens[0] = hello
tokens[1] = hi

Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> t
Please enter your sentence:
>hi!

tokens[0] = hi!

Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> h
Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
main.c: In function ‘main’:
main.c:41:6: error: a label can only be part of a statement and a declaration is not a statement
      char *temp = get_history(history, input[1]);
      ^~~~
main.c:42:6: error: expected expression before ‘char’
      char **tempTokenize = tokenize(temp);
      ^~~~
main.c:43:19: error: ‘tempTokenize’ undeclared (first use in this function); did you mean ‘tokenize’?
      print_tokens(tempTokenize);
                   ^~~~~~~~~~~~
                   tokenize
main.c:43:19: note: each undeclared identifier is reported only once for each function it appears in
make: *** [<builtin>: main.o] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  tokenizer       tokenizer.c   tokenizer.o
history.c~  main       main.o    #*shell*#  #tokenizer.c#   tokenizer.c~
history.h   main.c     Makefile  tester.c   #tokenizer.c#~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
main.c: In function ‘main’:
main.c:41:6: error: a label can only be part of a statement and a declaration is not a statement
      char *temp;
      ^~~~
make: *** [<builtin>: main.o] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
main.c: In function ‘main’:
main.c:42:67: error: expected ‘)’ before ‘;’ token
      char **tempTokenize = tokenize(get_history(history, input[1]););
                                                                   ^
make: *** [<builtin>: main.o] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> !1
Recalling history at: 49
item not found
Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' and then a number to get a certain sentence for the history, or 'e' to exit
> t
Please enter your sentence:
>hello in ty

tokens[0] = hello
tokens[1] = in
tokens[2] = ty

Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>hello hi fgw!

tokens[0] = hello
tokens[1] = hi
tokens[2] = fgw!

Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>hello gi d

tokens[0] = hello
tokens[1] = gi
tokens[2] = d

Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>qws

tokens[0] = qws

Program exited.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>hnjjjjn wmd lp

tokens[0] = hnjjjjn
tokens[1] = wmd
tokens[2] = lp

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./token
bash: ./token: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>Hello how are you

tokens[0] = Hello
tokens[1] = how
tokens[2] = are
tokens[3] = you

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>play today

tokens[0] = play
tokens[1] = today

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>no i wont!

tokens[0] = no
tokens[1] = i
tokens[2] = wont!

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
3
item not found
Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>hi how are you

tokens[0] = hi
tokens[1] = how
tokens[2] = are
tokens[3] = you

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>yo no more

tokens[0] = yo
tokens[1] = no
tokens[2] = more

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>yes i will

tokens[0] = yes
tokens[1] = i
tokens[2] = will

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>hello i

tokens[0] = hello
tokens[1] = i

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>hello ji dwef

tokens[0] = hello
tokens[1] = ji
tokens[2] = dwef

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  tokenizer       tokenizer.c   tokenizer.o
history.c~  main       main.o    #*shell*#  #tokenizer.c#   tokenizer.c~
history.h   main.c     Makefile  tester.c   #tokenizer.c#~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o history.o history.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>The cake is a lie!

tokens[0] = The
tokens[1] = cake
tokens[2] = is
tokens[3] = a
tokens[4] = lie!

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> It was good
Incorrect input, please try againEnter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>It was good

tokens[0] = It
tokens[1] = was
tokens[2] = good

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> no
Incorrect input, please try againEnter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>no

tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
0: (null)

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
0: (null)

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
2
item not found
Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> 
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  tokenizer       tokenizer.c   tokenizer.o
history.c~  main       main.o    #*shell*#  #tokenizer.c#   tokenizer.c~
history.h   main.c     Makefile  tester.c   #tokenizer.c#~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o history.o history.c
history.c: In function ‘add_history’:
history.c:36:7: error: ‘i’ undeclared (first use in this function)
   for(i = 0; i < len; i++) {
       ^
history.c:36:7: note: each undeclared identifier is reported only once for each function it appears in
history.c:41:14: error: ‘id’ undeclared (first use in this function); did you mean ‘i’?
   node->id = id++;
              ^~
              i
history.c:50:7: error: ‘current’ undeclared (first use in this function); did you mean ‘clearenv’?
       current = current->next;
       ^~~~~~~
       clearenv
make: *** [<builtin>: history.o] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o history.o history.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./token
bash: ./token: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>The cake is a lie!

tokens[0] = The
tokens[1] = cake
tokens[2] = is
tokens[3] = a
tokens[4] = lie!

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>It was good

tokens[0] = It
tokens[1] = was
tokens[2] = good

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>no

tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
1: The cake is a lie!

2: It was good

3: no


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
1: The cake is a lie!

2: It was good

3: no


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>Hello I am good

tokens[0] = Hello
tokens[1] = I
tokens[2] = am
tokens[3] = good

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
1: The cake is a lie!

2: It was good

3: no

4: Hello I am good


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
1
tokens[0] = The
tokens[1] = cake
tokens[2] = is
tokens[3] = a
tokens[4] = lie!

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> Incorrect input, please try againEnter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
4
tokens[0] = Hello
tokens[1] = I
tokens[2] = am
tokens[3] = good

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> Incorrect input, please try againEnter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> h
1: The cake is a lie!

2: It was good

3: no

4: Hello I am good


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
3
tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> Incorrect input, please try againEnter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to get a certain sentence from the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  tokenizer       tokenizer.c   tokenizer.o
history.c~  main       main.o    #*shell*#  #tokenizer.c#   tokenizer.c~
history.h   main.c     Makefile  tester.c   #tokenizer.c#~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
main.c: In function ‘main’:
main.c:42:6: error: a label can only be part of a statement and a declaration is not a statement
      char **tempTokenize = tokenize(get_history(history, input[1]));
      ^~~~
make: *** [<builtin>: main.o] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tok
bash: ./tok: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>h

tokens[0] = h

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: h


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>The cake is a lie!

tokens[0] = The
tokens[1] = cake
tokens[2] = is
tokens[3] = a
tokens[4] = lie!

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>But is was good

tokens[0] = But
tokens[1] = is
tokens[2] = was
tokens[3] = good

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>true

tokens[0] = true

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: The cake is a lie!

2: But is was good

3: true


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !1
Enter the id of the sentence you want to recall
item not found
Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>the cake is lie!

tokens[0] = the
tokens[1] = cake
tokens[2] = is
tokens[3] = lie!

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> it was good
Incorrect input, please try again
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>it was good

tokens[0] = it
tokens[1] = was
tokens[2] = good

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>no

tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: the cake is lie!

2: it was good

3: no


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !2
Enter the id of the sentence you want to recall
item not found
Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>The cake is a like!

tokens[0] = The
tokens[1] = cake
tokens[2] = is
tokens[3] = a
tokens[4] = like!

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>the is you

tokens[0] = the
tokens[1] = is
tokens[2] = you

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>no

tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: The cake is a like!

2: the is you

3: no


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
1
item not found
Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>cake is lie

tokens[0] = cake
tokens[1] = is
tokens[2] = lie

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>was good

tokens[0] = was
tokens[1] = good

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t no
Please enter your sentence:
>no

tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: cake is lie

2: was good

3: no


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
2
-827474352, id[0]item not found
Segmentation fault (core dumped)
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
main.c: In function ‘main’:
main.c:41:12: warning: passing argument 1 of ‘fgets’ from incompatible pointer type [-Wincompatible-pointer-types]
      fgets(id, 100, stdin);
            ^~
In file included from main.c:2:0:
/usr/include/stdio.h:564:14: note: expected ‘char * restrict’ but argument is of type ‘int *’
 extern char *fgets (char *__restrict __s, int __n, FILE *__restrict __stream)
              ^~~~~
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
main.c: In function ‘main’:
main.c:41:19: error: ‘pos’ undeclared (first use in this function); did you mean ‘puts’?
      scanf("%d", &pos)
                   ^~~
                   puts
main.c:41:19: note: each undeclared identifier is reported only once for each function it appears in
main.c:43:8: error: expected ‘;’ before ‘printf’
        printf("%d", pos);
        ^~~~~~
make: *** [<builtin>: main.o] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
main.c: In function ‘main’:
main.c:43:6: error: expected ‘;’ before ‘printf’
      printf("%d", id);
      ^~~~~~
make: *** [<builtin>: main.o] Error 1
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokk
bash: ./tokk: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>hello i am

tokens[0] = hello
tokens[1] = i
tokens[2] = am

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>it was good

tokens[0] = it
tokens[1] = was
tokens[2] = good

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t no
Please enter your sentence:
>no

tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: hello i am

2: it was good

3: no


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
2
2tokens[0] = it
tokens[1] = was
tokens[2] = good

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> Incorrect input, please try again
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: hello i am

2: it was good

3: no


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
3
3tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> Incorrect input, please try again
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>helo iam

tokens[0] = helo
tokens[1] = iam

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>yes you

tokens[0] = yes
tokens[1] = you

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: helo iam

2: yes you


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
2
Sentence at: 2 recalled
tokens[0] = yes
tokens[1] = you

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> Incorrect input, please try again
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> 2
Incorrect input, please try again
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> 3
Incorrect input, please try again
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ls
history.c   history.o  main.c~   README.md  tokenizer       tokenizer.c   tokenizer.o
history.c~  main       main.o    #*shell*#  #tokenizer.c#   tokenizer.c~
history.h   main.c     Makefile  tester.c   #tokenizer.c#~  tokenizer.h
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
main.c: In function ‘main’:
main.c:42:21: warning: passing argument 1 of ‘atoi’ makes pointer from integer without a cast [-Wint-conversion]
      int pos = atoi(id[0]);
                     ^~
In file included from main.c:1:0:
/usr/include/stdlib.h:104:12: note: expected ‘const char *’ but argument is of type ‘char’
 extern int atoi (const char *__nptr)
            ^~~~
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./token
bash: ./token: No such file or directory
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
make: 'tokenizer' is up to date.
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> make
cc    -c -o main.o main.c
gcc -o tokenizer history.o tokenizer.o main.o
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> ./tokenizer 
Hello, welcome to the tokenizer.
Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>Hello i am

tokens[0] = Hello
tokens[1] = i
tokens[2] = am

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>Yes you are

tokens[0] = Yes
tokens[1] = you
tokens[2] = are

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> t
Please enter your sentence:
>no

tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: Hello i am

2: Yes you are

3: no


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
1
Sentence at: 1 recalled
tokens[0] = Hello
tokens[1] = i
tokens[2] = am

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
2
Sentence at: 2 recalled
tokens[0] = Yes
tokens[1] = you
tokens[2] = are

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> !
Enter the id of the sentence you want to recall
3
Sentence at: 3 recalled
tokens[0] = no

Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> h
1: Hello i am

2: Yes you are

3: no


Enter a 't' if you would like to tokenize a sentence, 'h' to get the history, '!' to tokenize a certain sentence from the history, or 'e' to exit
> e

Closing the program...
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git add .
student@systems-vm:~/corg/f24-corg-tokenizer-AndyR-11/src> git commit -m "c